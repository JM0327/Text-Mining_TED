---
title: "Embedding"
author: "Ting Yang"
date: "09/12/2022"
output: html_document
---

```{r,include=FALSE}
source(here::here("scripts/setup.R"))
```

# Embedding

Except for the LSA and LDA, we also want to use embedding to analyze the TED video transcripts. Embedding refers to the representation of elements (documents or tokens) in a Vector Space Model. First we build a word embedding and then we build document embedding that inherits the word co-occurrence. properties.

## Word Embedding
The objective is to find a word embedding that reflects the co-occurrences. We use the fcm function from quanteta to compute word co-occurrence. 
```{r}
TED.coo <- fcm(TED.tk,
               context = "window",
               window = 5,
               tri = FALSE) 

TC <- head(TED.coo) %>% 
  convert(to="data.frame") %>% 
  select(1:6)

kable(TC,
      caption = "co-occurrence matrix") %>%
   kable_styling(bootstrap_options = "bordered") %>%
   kableExtra::scroll_box(width = "100%", height = "250px")
```
Here we show the first several rows of the result. For example, the co-occurrence of word *artificial* and *intelligence* is large(170). But the co-occurrence of word *fly* and *intelligence* is very small(0). 

```{r}
set.seed(123)
p <- 2 # word embedding dimension
TED.glove <- GlobalVectors$new(rank = p,
                               x_max = 10) # x_max is a needed technical option
TED.we <- TED.glove$fit_transform(TED.coo) # central vectors; speech.glove$components contains the context vectors
TED.we <- t(TED.glove$components) + TED.we# unique representation
```
For the visualization, we draw two plots. The first one is plotting the vectors of the 100 most used words (100 largest frequencies). The second one is plotting all the words but only labeling part of it.

```{r}
index <- textstat_frequency(dfm(TED.tk))[1:100, ]$feature
## words with the 100 largest frequencies
```

```{r top100 most used words map}
data.for.plot <- data.frame(TED.we[index, ])
data.for.plot$word <- row.names(data.for.plot)

Emb_p1 <- ggplot(data.for.plot, 
       aes(x = X1,
           y = X2,
           label = word)) +
  geom_text_repel(max.overlaps = 100)+
  theme_void() +
  labs(title="map of top100 words")
```

```{r}
TED.we.df <- as.data.frame(TED.we)
word <- rownames(TED.we.df)
TED.we.df <- cbind(word,TED.we.df)
e <- c(1:15045)
row.names(TED.we.df) <- e
```

```{r all words map}
Emb_p2 <- ggplot(TED.we.df,aes(x=V1,y=V2))+
  geom_text_repel(data = subset(TED.we.df, V1 <=-1.8|V2>3|V1>2),
            mapping = aes(label = word),
            hjust = "inward",
            max.overlaps = 100) +
  geom_point(color="grey")+
  labs(title="map of all words(partially labeled)")
```

```{r}
Emb_p1
```

```{r}
Emb_p2
```

We use the geom_text_repel() function to avoid overlapping labels between data points. Some labels show a black line next to them, pointing to the location of the point marked by that label. 

First plot: Words that are close on the map are often used together. For example, the word "robot" and "computer" are close which means they are usually used together. And the word "man" and "woman" are close so they are also usually used together.

Second plot: We also want to check the distribution of all words so we draw this second plot.
This plot shows all the used words in grey and labels a part of words for illustration. According to the plot, the word "carbon" and "emission" are close so these two words are usually used together. 

# Document Embedding

We now build the document embedding by computing the centroids of the documents.

```{r}
kable(TED.we[TED.tk[[1]], ],
      col.names = c("dimension1","dimension2"),
      caption = "word vectors") %>%
   kable_styling(bootstrap_options = "bordered") %>%
   kableExtra::scroll_box(width = "100%", height = "250px")
```


```{r}
nd <- length(TED.tk) # number of documents
TED.de <- matrix(nr = nd, nc = p) # document embedding matrix (1 document per row)
for(i in 1:nd) {
  words_in_i <- TED.we[TED.tk[[i]], , drop = FALSE] 
  # drop = FALSE is needed in case there is only one token
  TED.de[i, ] <- apply(words_in_i, 2 ,mean)
}
row.names(TED.de) <- names(TED.tk)
```


```{r}
kable(TED.de,
      col.names = c("dimension1","dimension2"),
      caption = "document vectors") %>%
   kable_styling(bootstrap_options = "bordered") %>%
   kableExtra::scroll_box(width = "100%", height = "250px")
```

Now, we make the representation of the documents and use different color to represent the document in diffrent category.
```{r}
TED.de <- as.data.frame(TED.de)
TED.de.source <- TED_full %>% 
  select(2,3,4) %>% cbind(TED.de) 

ggplot(data=TED.de.source,mapping = aes(
  x=V1,
  y=V2,
  color=cate))+
  geom_point()+
  labs(x = "dimension1",
    y = "dimension2")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )
```
According to this plot, the documents in the category "AI" and "relationships" covers the largest area of each other. So maybe the documents in these two categories are more similar when compared with the documents in the category "Climate change".


