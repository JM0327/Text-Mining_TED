---
title: "Topic modeling"
author: "Ting Yang"
date: "05/12/2022"
output: html_document
---

# LSA

## LSA on TF
First, we build the LSA object and use 4 dimensions.And we check the *Doc-topic sim*, *Topic strength* and *Terms-topic sim*.
```{r}
TED.lsa <- textmodel_lsa(x = TED.dfm,nd = 4) 

head(TED.lsa$docs)
```

```{r}
head(TED.lsa$sk)
```



```{r}
head(TED.lsa$features)
```
The first dimension is often correlated to (of little information and often not represented.) the document length and the frequency of the term. So we check the top words for dimension2, 3, and 4.
```{r}
n.terms <- 5
## For Dimension 2
w.order <- sort(TED.lsa$features[, 2],decreasing = TRUE)
w.top.d2 <- c(w.order[1:n.terms],rev(rev(w.order)[1:n.terms]))
## For Dimension 3
w.order <- sort(TED.lsa$features[, 3], decreasing = TRUE)
w.top.d3 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))
## For Dimension 4
w.order <- sort(TED.lsa$features[,4], decreasing = TRUE)
w.top.d4 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))
```

```{r}
w.top.d2
```
Dimension 2 is associated positively with word like "say", "people", "know", "love" ,"think", and negatively associated with "human", "datum", "use", "ai", "can".


```{r}
w.top.d3
```
Dimension 3 is associated positively with word like "climate", "year", "need", "change" ,"energy", and negatively associated with "like", "think", "robot", "human", "ai".


```{r}
w.top.d4
```
Dimension 3 is associated positively with word like "robot", "can", "see", "like" ,"go", and negatively associated with "company", "good", "people", "human", "ai".

? why all the topics are negatively associated with "human", "ai"


I combine the LSA result with the category of document and I represent every document on these two following plots. 
```{r}

TED.lsa.source <- TED_full %>% 
  select(2) %>% cbind(as.data.frame(TED.lsa$docs))

ggplot(data=TED.lsa.source,mapping = aes(
  x=V2,
  y=V3,
  color=cate))+
  geom_point()+
  labs(x = "dimension2",
    y = "dimension3")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )
```
First plot:x-axis is dimension 2 and y-axis is dimension3.
According to this plot, most of the documents of category "Climate change" are positively associated with dimension3. Most of the documents of category "Relationships" are positively associated with dimension2

```{r}
ggplot(data=TED.lsa.source,mapping = aes(
  x=V3,
  y=V4,
  color=cate))+
  geom_point()+
  labs(x = "dimension3",
    y = "dimension4")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )
```
Second plot:x-axis is dimension 3 and y-axis is dimension4.
According to this plot, most of the documents of category "Climate change" are positively associated with dimension3. Compare with the documents of other two categories, the documents of category "AI" are mostly associated with dimension4.

## LSA on TF-IDF

```{r}
TED.lsa2 <- textmodel_lsa(TED.tfidf, nd = 4) 
```


```{r}
head(TED.lsa2$docs)
```


```{r}
head(TED.lsa2$sk)
```

```{r}
head(TED.lsa2$features)
```

```{r}
## For Dimension 2
w2.order <- sort(TED.lsa2$features[, 2],decreasing = TRUE)
w2.top.d2 <- c(w2.order[1:n.terms],rev(rev(w2.order)[1:n.terms]))
## For Dimension 3
w2.order <- sort(TED.lsa2$features[, 3], decreasing = TRUE)
w2.top.d3 <- c(w2.order[1:n.terms], rev(rev(w2.order)[1:n.terms]))
## For Dimension 4
w2.order <- sort(TED.lsa2$features[, 4], decreasing = TRUE)
w2.top.d4 <- c(w2.order[1:n.terms], rev(rev(w2.order)[1:n.terms]))
```

```{r}
w2.top.d2
```

```{r}
w2.top.d3
```

```{r}
w2.top.d4
```

```{r}
TED.lsa2.source <- TED_full %>% 
  select(2) %>% cbind(as.data.frame(TED.lsa2$docs))

ggplot(data=TED.lsa2.source,mapping = aes(
  x=V2,
  y=V3,
  color=cate))+
  geom_point()+
  labs(x = "dimension2",
    y = "dimension3")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )
```


```{r}
ggplot(data=TED.lsa2.source,mapping = aes(
  x=V3,
  y=V4,
  color=cate))+
  geom_point()+
  labs(x = "dimension3",
    y = "dimension4")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )
```



# LDA
Now I turn to Latent Dirichlet Association (LDA) and choose 3 dimensions.
```{r}
TED.LDA <- LDA(
  convert(TED.dfm, to = "topicmodels"),
  k = 3)
```

First, I check the top10 words in each dimensions.
```{r}
topicmodels::terms(TED.LDA, 10)
```
Then I create a table to show the number of documents in each dimension.
```{r}
topicmodels::topics(TED.LDA)%>% table()
```

Then I use the topic_diagnostics function to diagnose the *prominence*, *coherence* and *exclusivity* of each dimension.
```{r}
topic_diagnostics(
  topic_model = TED.LDA, 
  dtm_data = convert(TED.dfm, to = "topicmodels"))
```
?Why the doc_prominence is different from the TED.lsa$sk value? Both of them are the strength of topic

Topic 3 has the largest topic coherence and Topic 4 has the smallest topic coherence.

Topic 4 has the largest topic exclusivity and Topic 2 has the smallest topic exclusivity.


```{r}
beta.long <- tidy(
  TED.LDA,
  matrix = "beta") # equivalent to melt (with this package)

beta.long %>% 
  group_by(topic) %>% 
  top_n(15, beta) %>% 
  ggplot(aes(reorder_within(term, beta, topic), beta)) + 
  geom_col(show.legend = FALSE) +
  coord_flip()+
  facet_wrap(~ topic, scales = "free_y") +
  scale_x_reordered() + 
  xlab("Term") +
  theme(
    axis.text.y = element_text(size = 8),
    axis.text.x = element_text(size = 8),
    strip.text = element_text(size = 8))
```

```{r}

document <- rownames(TED.lsa.source)
TED.lsa.source <- cbind(document,TED.lsa.source)

gamma.long <- tidy(TED.LDA,matrix = "gamma") %>% 
  right_join(TED.lsa.source[1:2])

gamma.long$cate<-factor(gamma.long$cate,
                       levels = c('1','2','3'),
                       labels = c("AI","Climate change","Relationships"))

gamma.long %>% ggplot(mapping = aes(x=document,y=gamma,fill=cate))+
  geom_col()+
  coord_flip() + 
  facet_wrap(~topic,ncol = 4)
  
  
```

Topic2 focus on "people", "know", "like", "love".
Topic3 focus on "think", "like", "human", "robot".
Topic4 focus on "year", "energy", "energy", "water"
The *Relationships* related documents mainly talk about Topic 2.
The *AI* related documents mainly talk about Topic3.
The *Climate change* related documents mainly talk about Topic4.

# Supervised learning(LSA on TF)

```{r}
a <- c(1:1471)
row.names(TED.lsa.source) <- a
TED.lsa.source$cate <- as.factor(TED.lsa.source$cate) 
```


```{r}
set.seed(123)
index.tr <- createDataPartition(y = TED.lsa.source$cate, p= 0.8, list = FALSE)
TED.tr <- TED.lsa.source[index.tr,]
TED.te <- TED.lsa.source[-index.tr,]
```

## Balance the data

```{r}
table(TED.tr$cate)
```
The data is unbalanced.
We use the subsampling method to balance the data

```{r}
set.seed(123)
n2 <- min(table(TED.tr$cate)) ## 327

TED.tr.1 <- filter(TED.tr, cate=="1") ## the category 1
TED.tr.2 <- filter(TED.tr, cate=="2") ## the category 2
TED.tr.3 <- filter(TED.tr, cate=="3") ## the category 3
index.1 <- sample(size=n2, x=1:nrow(TED.tr.1), replace=FALSE)
index.3 <- sample(size=n2, x=1:nrow(TED.tr.3), replace=FALSE)
TED.tr.subs <- data.frame(rbind(TED.tr.1[index.1,], 
                                TED.tr.2,
                                TED.tr.3[index.3,]))
```


```{r}
table(TED.tr.subs$cate)
```

```{r}
TED.fit <- ranger(TED.tr.subs$cate ~ ., 
                     data = TED.tr.subs[2:6])
pred.te <- predict(TED.fit, TED.te)
confusionMatrix(data=pred.te$predictions, reference = TED.te$cate)
```

# Supervised learning(LSA on TF-IDF)
```{r}
TED.lsa2.source <- cbind(document,TED.lsa2.source)
row.names(TED.lsa2.source) <- a
TED.lsa2.source$cate <- as.factor(TED.lsa2.source$cate)
```

```{r}
set.seed(123)
index.tr <- createDataPartition(y = TED.lsa2.source$cate, p= 0.8, list = FALSE)
TED.tr <- TED.lsa2.source[index.tr,]
TED.te <- TED.lsa2.source[-index.tr,]
```

```{r}
n2 <- min(table(TED.tr$cate)) ## 327

TED.tr.1 <- filter(TED.tr, cate=="1") ## the category 1
TED.tr.2 <- filter(TED.tr, cate=="2") ## the category 2
TED.tr.3 <- filter(TED.tr, cate=="3") ## the category 3
index.1 <- sample(size=n2, x=1:nrow(TED.tr.1), replace=FALSE)
index.3 <- sample(size=n2, x=1:nrow(TED.tr.3), replace=FALSE)
TED.tr.subs <- data.frame(rbind(TED.tr.1[index.1,], 
                                TED.tr.2,
                                TED.tr.3[index.3,]))
```


```{r}
TED.fit2 <- ranger(TED.tr.subs$cate ~ ., 
                     data = TED.tr.subs[2:6])
pred.te <- predict(TED.fit2, TED.te)
confusionMatrix(data=pred.te$predictions, reference = TED.te$cate)
```

