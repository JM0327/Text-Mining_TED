---
title: "eda"
author: "Manunpat"
date: "2022-12-10"
output: html_document
---

```{r,include=FALSE}
source(here::here("scripts/setup.R"))
```

# 4. EDA   

-Analysis of the word frequencies: compute and show frequencies and TF-IDF.
-Comparison of the speeches in terms of lexical diversity
-Comparison of two speeches in terms of key words (in the answer below Trump=target vs. Obama=reference).
-Show links between terms (compute co-occurrences and try to build a network)

# Plot of Frequencies and TF-IDF
-because we have 3 different topics so we dont expect topic specific words in the most frequent used terms. Altho we can see some words related to our topic like love, ai, kind, world, human
```{r}
TED.freq1 %>% 
  top_n(20, frequency) %>%
  ggplot(aes(
    x = reorder(feature, frequency),
    y = frequency)) + 
  geom_bar(stat = "identity") +
  coord_flip() + #change x y axis
  ylab("Frequency") + 
  xlab("term")
```


```{r}

textplot_wordcloud(TED.dfm1) 

```

Text 12: EM = Elon Musk, CA = Chris Anderson: Both words have high TFIDF because they are specific to this text.
```{r}
TED.tfidf1 %>% 
  tidy() %>% 
  top_n(10, count) %>% #may change to top 10
  ggplot(aes(x = term, y = count)) + 
  geom_col() + 
  coord_flip() + 
  theme(axis.text.y = element_text(size = 4),
        axis.ticks.y = element_blank())  + 
  facet_wrap(~document, ncol = 2)

#TED$tanscript[12]

```

link to the number of sample we have in cate: numbers of Relationships vdo are the highest among the others 
```{r}
TED.tfidf1 %>% 
  tidy() %>%
  group_by(term) %>%
  summarize(count = max(count)) %>% #use summarize to find max
  ungroup() %>% 
  arrange(desc(count)) %>%
  top_n(20, count) %>%
  ggplot(aes(x=reorder(term, count),
             y = count)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Max TF-IDF") + 
  ylab("term")
```


# Lexical Diversity
TTR: The lexical diversity analysis is conclusive for these data. We can see that text237, text131 have the highest richness of vocabulary among the other documents.

```{r}
ttr_top <- TED.dfm1 %>% textstat_lexdiv() %>% arrange(desc(TTR)) %>% top_n(10, TTR)
ttr_bottom <- TED.dfm1 %>% textstat_lexdiv() %>% arrange(desc(TTR)) %>% top_n(-10, TTR)

TED.dfm1 %>% textstat_lexdiv() %>% 
  ggplot(aes(reorder(document, -TTR),
             TTR)) + 
  geom_bar(stat="identity") +
  xlab("Text")
```

Find another way to set up window or remove?
```{r}
# TED.tk1 %>% textstat_lexdiv(
#   measure = "MATTR",
#   MATTR_window = 20)
# 
# TED.tk1 %>% 
#   textstat_lexdiv(
#     measure = "MATTR",
#     MATTR_window = 20) %>% 
#   ggplot(aes(reorder(
#     document, -MATTR),
#     MATTR)) + 
#   geom_bar(stat="identity") +
#   xlab("Text")
```

# Keyness
Do one chart per topic

AI
we can see that the keyness of terms in text1 compared to all the others include unsupervised supervised patient treatment. 
```{r}
TED.keyness <- textstat_keyness(
  TED.dfm1,
  target = "text1")

textplot_keyness(TED.keyness, labelsize = 3) 
```

# Link between Words

The larger the value the more often two words occur together (in documents).

We now restrict the analysis to some terms as, otherwise, the result will be impossible to read. First, we restrict to the terms that have a frequency larger than 500
```{r}
TED.co <- fcm(TED.tk1, 
                context = "document", 
                tri = FALSE)
TED.co
```

```{r}
#create index = words that have frequency > 8
index <- TED.freq1 %>% 
  filter(frequency > 500) %>% 
  data.frame() %>% 
  select(feature)

#then refer them to co occurance table
x <- TED.co[index$feature, index$feature]
x
```

To make a chart is possible to read, we decide that for less than 4500 co-occurences, there is no link (larger than 4500, there is one link).
“make”, "thing", "people" are the central terms that co-occurs a lot with the others. They are common words in TED talk. Due to 3 different topics, similar to the other charts, we do not expect to see the specific words for each topic in this analysis.

For "climate", there is no co-occurance larger than 4500 but it's still in the word with frequency more than 500.

```{r}
x[x <= 4500] <- 0
x[x > 4500] <- 1

network <- graph_from_adjacency_matrix(
  x,
  mode = "undirected",
  diag = FALSE)
plot(network,
     layout = layout_with_kk)

```



