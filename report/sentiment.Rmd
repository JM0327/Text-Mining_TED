---
title: "Sentiment analysis"
---

In this part, we use two dictionary: AFINN, NRC and method of Valence-Shifters to do sentiment analysis for every video's transcript, which means we don't split the transcript by every 20 sentences. It might be better to see if the sentiment of video would influence the other features. Here, we have following hypothesis:   

- The sentiment of videos are related to the corresponding topic. Topic like AI may have more positive sentiment.   
- The sentiment of videos influence users giving likes. Positive videos usually have more likes.  
- The sentiment of videos changed over years, since it might related to the corresponding affairs.    


```{r}
# resume cate, better to interpret 
TED_sentiment$cate <- gsub("1","AI",TED_sentiment$cate)
TED_sentiment$cate <- gsub("2","Climate change",TED_sentiment$cate)
TED_sentiment$cate <- gsub("3","Relationships",TED_sentiment$cate)

# since sentiment analysis cannot use cleaned data after stemming, so here use another way to tokenize again
TED.tok <- unnest_tokens(
  TED_sentiment,
  output = "word",
  input = "tanscript",
  to_lower = TRUE,
  strip_punct = TRUE,
  strip_numeric = TRUE)
TED.tok <- TED.tok %>% filter(word != "laughter" | word != "applaud")
```

## Sentiment Based    

First, we use NRC method to check the sentiment description of each videos transcript. as it's sentiment based method, we would like to only check the relationship with videos' topics and their likes.   

```{r}
# NRC
# join the corresponding sentiment qualifier in “nrc” 

TED.sent.nrc <- 
  inner_join(
    TED.tok,
    get_sentiments("nrc"),
    by = c("word" = "word"))

head(TED.sent.nrc, 5) %>% flextable() %>% autofit()

```

### Sentiment v.s. Likes     

Since there are near to 300 transcript (videos), we would like to extract 20 videos with the most likes and the least likes, respectively.         


```{r}
# Sub data for checking Video likes topic
TED.nrc <- TED.sent.nrc %>% 
  group_by(title,cate,likes,sentiment) %>% summarise(n=n())

# too many text, hard to read
# extract top 20, tail 20 transcipt to check their sentiment
toplike20 <- TED.nrc[order(TED.nrc$likes,decreasing = T),][1:200,]
taillike20 <- TED.nrc[order(TED.nrc$likes,decreasing = F),][1:200,]

# top
toplike20%>%
  ggplot(mapping = aes(x = sentiment, y=n, fill = sentiment)) + 
  geom_bar(stat = "identity",
           alpha = 0.8) + 
  facet_wrap(~ title) + 
  coord_flip()+
  theme(legend.position = 'bottom')+
  labs(y="the number of sentiment")

# tail
taillike20%>%
  ggplot(mapping = aes(x = sentiment, y=n, fill = sentiment)) + 
  geom_bar(stat = "identity",
           alpha = 0.8) + 
  facet_wrap(~ title) + 
  coord_flip()+
  theme(legend.position = 'bottom')+
  labs(y="the number of sentiment")
  
```


**Re-scale sentiment by their length:**   

```{r}

# the frequencies of sentiments are computed, by document
TED.sent.nrc.total <- TED.sent.nrc %>% 
  group_by(title,likes) %>% 
  summarize(Total = n()) %>% 
  ungroup()

#top
left_join(
  TED.sent.nrc,
  TED.sent.nrc.total)%>% 
  filter(title %in% toplike20$title) %>%
  group_by(title, sentiment) %>%  
  summarize(n = n(),
            Total = unique(Total)) %>%
  ungroup() %>% 
  mutate(relfreq = n / Total) %>%
  ggplot(aes(
    x = sentiment,
    y = relfreq,
    fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ title) + 
  coord_flip()+
  theme(legend.position = 'bottom')+
  labs(y="the number of sentiment")

#tail
left_join(
  TED.sent.nrc,
  TED.sent.nrc.total)%>% 
  filter(title %in% taillike20$title) %>%
  group_by(title, sentiment) %>%  
  summarize(n = n(),
            Total = unique(Total)) %>%
  ungroup() %>% 
  mutate(relfreq = n / Total) %>%
  ggplot(aes(
    x = sentiment,
    y = relfreq,
    fill = sentiment)) + 
  geom_bar(stat = "identity", alpha = 0.8) + 
  facet_wrap(~ title) + 
  coord_flip()+
  theme(legend.position = 'bottom')+
  labs(y="the number of sentiment")
```

In this part, we did NRC method in two different ways, one without scaling and another with re-scaling the sentiment by their length in the documents.    

No matter in which way we can see that there are no obvious difference among the videos with the most likes and the least likes, in terms of their likes. Positive and anticipation appearing in everywhere. In some top 20 videos, we could also see the negative and fear sentiment with relatively high levels.       

### Sentiment v.s. Topics    

we would like to check what is the more frequent sentiment appearing in each topics. we suppose the topic like climate change is more related to negative or fear sentiment, and for the topic like AI, we could see anticipation or positive sentiment more frequent.   

```{r}
# it is hard to check the sentiment for each video, then check it for each cate

TED.nrc %>% 
  group_by(cate,sentiment) %>%
  summarise(cate_n = sum(n)) %>%
  ggplot(mapping = aes(subgroup = cate, fill = interaction(sentiment, cate), area = cate_n)) +
  geom_treemap(color="white", size=0.5*.pt, alpha=NA) +
  geom_treemap_subgroup_text(
    place = "center", alpha = 0.5, grow = TRUE) + 
  geom_treemap_text(mapping = aes(
    label = sentiment), 
    color = "white",
    place = "center", grow = FALSE) +
  guides(fill = FALSE)

```

As we assume, The topic of AI is often accompanied by positive and anticipation, and we could not ignore trust. Yet, we could see that negative also accounts for a not small part. Contrary to our speculation, the topic of climate change has the same positive sentiment which is also the most frequent part in this topic. And, each sentiment is more evenly distributed in the videos on the topic of relationships, even though the positive sentiment is still the most.    

In this case, we begin to assume that positive sentiment actually is the main sentiment in TED talk showing in all videos, based on previous analysis.    

### Value-Based    

Thus, except for the initial assumption, we would like to check one more assumption - if the positive sentiment appears in all videos, by using the value-based method: Afinn.    


```{r}
# Afinn

TED.sent.afinn <- 
  inner_join(
    TED.tok,
    get_sentiments("afinn"),
    by = c("word" = "word"))

# calculate the average score per documen
# TED.sent.afinn %>% 
#   group_by(title) %>% 
#   summarize(Score = mean(value)) %>% 
#   ungroup() %>% 
#   arrange(Score) %>% 
#   flextable() %>% 
#   autofit() 
```

```{r, fig.height=15}
TED.sent.afinn %>% 
  group_by(title) %>% 
  summarize(Score = mean(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = reorder(title, Score), y = Score)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  ylab("Mean Sentiment Score") +
  xlab("")

```

here, we calculated the average sentiment score per video. We can see that the number of videos transcript with positive and negative values is very disparate. Thus, TED talk do prefer giving positive videos.      

```{r}
#extract the top and tail videos
video_sentiscore <- TED.sent.afinn %>% 
  group_by(title) %>% 
  summarize(Score = mean(value))

# video_sentiscore[order(video_sentiscore$Score,decreasing = T),][1:10,]
# video_sentiscore[order(video_sentiscore$Score,decreasing = F),][1:10,]
```

### Sentiment v.s. Likes    

```{r}
TED.sent.afinn.like <- TED.sent.afinn %>% 
  group_by(title,cate,likes) %>% 
  summarize(Score = mean(value))

TED.sent.afinn.like %>% ggplot(aes(x=likes,y=Score,color = cate))+
  geom_line() +
  facet_wrap(~cate, nrow = 3,scales = 'free')+
  theme(legend.position = 'bottom')
```

Since the number of likes for each video is relatively similar, and only individual videos have a large number of likes, we separate each category to observe the distribution of the number of likes and sentiment values. We can observe there are no obvious pattern as well. Only some videos in Climate change topic have negative sentiment and the less numbers of likes.      


### Sentiment v.s. topics        

```{r}
TED.sent.afinn.cate <- TED.sent.afinn %>% 
  group_by(title,cate) %>% 
  summarize(Score = mean(value))

TED.sent.afinn.cate %>% 
  ggplot(mapping = aes(x = cate, y = Score))+
  geom_boxplot()+
  labs(x="Topics")
```

The sentiment values for each topic are relatively similar, and they are all in the upper-middle range - more positive. Among the topics of climate change and AI, the sentiment value of each video is more evenly distributed. AI topic has two outliners with lowest values, the most negative.     

### Videos' sentiment over years   

```{r}
TED.sent.afinn.year <- TED.sent.afinn 
TED.sent.afinn.year$posted <- year(TED.sent.afinn.year$posted)

TED.sent.afinn.year <- TED.sent.afinn.year %>% 
  group_by(cate,posted) %>% 
  summarize(Score = mean(value))

TED.sent.afinn.year %>% ggplot(aes(x=posted,y=Score,color=cate))+
  geom_line()+
  theme(legend.position = 'bottom')+
  labs(x="Posted Year")
```

The talks on relationship topics have great fluctuations. Its mean sentiment value reached the lowest values before 2005 and around 2013. Climate change related topics have seen a decline in mean sentiment value in recent years. Yet, It is worth noting that the positive value of videos posted after 2020 is getting higher.    

### Sentiment Analysis using Valence-Shifters   

Meantime, we would like to check if there is a huge difference after using valence-shifters.     

```{r}
## split by sentences
TED_sentiment_text <- get_sentences(TED_sentiment$tanscript)
## Compute the sentiment by sentences
TED.senti <- sentiment(TED_sentiment_text)
## Prepare a tibble for the plot
TED.senti <- as_tibble(TED.senti)
## Plot the sentiment curve by sentences
# TED.senti %>% 
#   # group_by(element_id) %>%
#   ggplot(aes(x = sentence_id, y = sentiment)) + 
#   geom_line() + 
#   facet_wrap(~ element_id) 
```

```{r}
TED.sentdoc <- sentiment_by(TED_sentiment$tanscript)

TED.sentdoc %>% 
  mutate(Document = factor(paste("Doc_", element_id, sep = ""))) %>% 
  ggplot(aes(x = reorder(Document, ave_sentiment),
             y = ave_sentiment)) + 
  geom_bar(stat="identity") + 
  coord_flip() +
  xlab("") +
  ylab("Average Sentiment Score")
```

```{r}
#check the difference between afinn method and Valence-Shifters
#check the number of doc with score < 0 

nagative_VF <- sum((TED.sentdoc$ave_sentiment <0) == T)

negative <- TED.sent.afinn %>% 
  group_by(title) %>% 
  summarize(Score = mean(value)) %>%
  filter(Score < 0 )

nagative <- length(negative$title)

# [1] 19
# [1] 31
```

First, we can see that the sentiment values are distributed as similar as the one without using Valence-Shifters. After counting the number of videos transcripts with negative values, we found there are 31 videos having negative values before taking negative form into account, and 19 videos having negative values after considering negative form.    



