---
title: "web"
author: "Jiaming"
date: "2022-11-17"
output: html_document
---

```{r,include=FALSE}
source(here::here("scripts/setup.R"))
```

```{r bbc web}
rD <- rsDriver(browser="chrome", port=4547L, verbose=F)

remDr <- rD$client
url <- "https://www.bbc.co.uk/learningenglish/english/features/6-minute-english"
remDr$navigate(url)

html_page <- remDr$getPageSource()[[1]]
```

```{r}
#capture all article titles
#since there are no independent list of all video that we wanteed to analyze before in the youtube channel, so i first crawl the title of each video over BBC website, then search on youtube
title <- read_html(html_page) %>% 
  html_nodes(".widget-progress-enabled a") %>% 
  html_text() %>%
  as.data.frame() %>%
  filter(. != "")
names(title) <- "title_name"

Sys.sleep(2)
```

```{r youtube bbc}
# now, move to youtube
url <- "https://www.youtube.com/@bbclearningenglish/featured"
remDr$navigate(url)

html_page <- remDr$getPageSource()[[1]]

Sys.sleep(2)
```

```{r}
#accept cookies
remDr$findElement(using = 'xpath', '//*[@id="yDmH0d"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/form[2]/div/div/button/span')$clickElement()

Sys.sleep(2)
```


```{r}

sub_page_title <- as.character()
posting_time <- as.character()
views_times <- as.character()
transcrip_text <- as.character()


#n<- length(title$title_name)

n<-10 #normally, we should use the code above, now, use 10 to try. 

for (i in 1:n) {
  #search article titles
  search_icon <- remDr$findElement(using = 'xpath', '//*[contains(concat( " ", @class, " " ), concat( " ", "ytd-expandable-tab-renderer", " " ))]')
  search_icon$clickElement()
  
  search_box <- remDr$findElement(using = 'xpath', '//*[@id="input-1"]/input')
  search_box$clickElement()
  
  search_box$clearElement()
  search_box$sendKeysToElement(list(title[i,1], key = "enter"))
  
  Sys.sleep(2)
  
  #click the first matching output
  remDr$findElement(using = 'xpath', '//*[@id="video-title"]/yt-formatted-string')$clickElement()
  Sys.sleep(2)
  
  #click expand to read more video infos
  remDr$findElement(using = 'xpath', '//*[@id="expand"]')$clickElement()
  Sys.sleep(10)
  
  #open subtitle to be ready to read all infos
  subtitle_dropdown <- remDr$findElement(using = 'xpath', '//*[@id="button-shape"]/button/yt-touch-feedback-shape/div/div[2]')
  remDr$mouseMoveToLocation(webElement = subtitle_dropdown)
  remDr$click(2)
  Sys.sleep(5)
  
  remDr$findElement(using = 'xpath', '//*[@id="items"]/ytd-menu-service-item-renderer[2]/tp-yt-paper-item/yt-formatted-string')$clickElement()
  Sys.sleep(2)
  
  # capture the detailed infos 
  
  sub_page <- remDr$getPageSource()[[1]]
  
  video_title <- read_html(sub_page) %>% 
    html_nodes(xpath = "//*[@id='title']/h1/yt-formatted-string") %>% 
    html_text() 
  
  video_posting_time <- read_html(sub_page) %>% 
    html_nodes(xpath ="//*[@id='info']/span[3]") %>% 
    html_text() 
  
  video_views_times <- read_html(sub_page) %>% 
    html_nodes(xpath ="//*[@id='info']/span[1]") %>% 
    html_text() 
  
  transcript <- read_html(sub_page) %>% 
    html_nodes(xpath ="//*[@id='content']/ytd-transcript-search-panel-renderer") %>% 
    html_text() 
  #transcrip_text <- transcrip_text[2]
  
  remDr$goBack()
  
  sub_page_title <- append(sub_page_title,video_title)
  posting_time <-  append(posting_time,video_posting_time)
  views_times <-  append(views_times,video_views_times)
  transcrip_text <-  append(transcrip_text,transcript)

}
```

```{r}
#group all infos into one dataframe

six_mins_youtube <- data.frame(
  
  "title in youtube" = sub_page_title,
  "posting time" = posting_time,
  "views time" = views_times,
  "text" = transcrip_text
  
)

six_mins_youtube$title.in.youtube <- gsub(" - 6 Minute English","", six_mins_youtube$title.in.youtube)
names(six_mins_youtube)[1] <- "title_name"

six_mins <- left_join(title, six_mins_youtube, by="title_name")

```



```{r, include=FALSE}
remDr$closeServer()
remDr$close()
rm(remDr)
rm(rD)
gc()
```